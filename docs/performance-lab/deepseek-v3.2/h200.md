# Optimizing DeepSeek-V3.2 Throughput on NVIDIA H200 GPUs

## Conclusion

![DeepSeek-V3.2 H200 Throughput Optimization](../../assets/performance-lab/deepseek-v3.2-h200.png)
Recommended configuration for optimizing throughput of DeepSeek-V3.2 on a single node with H200x8:

???+ tip "Serving Command"
    ```bash
    python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-V3.2 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8 --dp-size 8 --enable-dp-attention
    ```

Link for [tool_chat_template_deepseekv32.jinja](https://github.com/sgl-project/sglang/blob/main/examples/chat_template/tool_chat_template_deepseekv32.jinja)

Comparison of benchmark results before and after optimization:

| Benchmark Case | baseline (vLLM without any optimizations) | Optimized |
|---------------|--------------------------------------------|-----------|
| **ShareGPT** | Total TPS: 4113.24<br>Mean TPOT(ms): 613.22 | Total TPS: 7351.59 <span style="background-color:lightgreen;">(+78.8%)</span><br>Mean TPOT(ms): 287.86 |
| **Short Prompt** | Total TPS: 10539.36<br>Mean TPOT(ms): 747.47 | Total TPS: 19778.53 <span style="background-color:lightgreen;">(+87.7%)</span><br>Mean TPOT(ms): 753.97 |
| **Medium Prompt** | Total TPS: 10488.24<br>Mean TPOT(ms): 375.72 | Total TPS: 27385.86 <span style="background-color:lightgreen;">(+161.1%)</span><br>Mean TPOT(ms): 200.06 |
| **Long Prompt** | Total TPS: 9313.06<br>Mean TPOT(ms): 245.07 | Total TPS: 20094.60 <span style="background-color:lightgreen;">(+115.8%)</span><br>Mean TPOT(ms): 171.34 |
| **Very Long Prompt** | Total TPS: 9789.64<br>Mean TPOT(ms): 463.89 | Total TPS: 20022.76 <span style="background-color:lightgreen;">(+104.5%)</span><br>Mean TPOT(ms): 245.69 |
| **Ultra Long Prompt** | Total TPS: 6288.25<br>Mean TPOT(ms): 619.71 | Total TPS: 16442.29 <span style="background-color:lightgreen;">(+161.5%)</span><br>Mean TPOT(ms): 51.45 |
| **Generation-Heavy Prompt** | Total TPS: 3112.52<br>Mean TPOT(ms): 45.72 | Total TPS: 3611.95 <span style="background-color:lightgreen;">(+16.0%)</span><br>Mean TPOT(ms): 40.25 |

!!! note
    1. Our benchmark tests do not cover all possible optimization combinations. For example, we select the inference engine that performs best under its default configuration as the starting point for further tuning. This pruning approach yields a local optimum, which may not be the global optimum.
    2. There are other optimization methods that depend on specific user scenarios, including max batch size, schedule configuration, extended KV cache, CUDA graph, etc. The conclusions in this document can serve as a starting point for more targeted optimizations.
    3. The tests are conducted on specific hardware and software setups. Advances in the inference engine may lead to new conclusions.

If there are any missing points or updates reflecting new changes, please [let us know](https://github.com/gpustack/gpustack/issues/new/choose).


## Optimization Objective

Achieve high throughput under high-concurrency request scenarios.

## Experimental Setup

### Model

deepseek-ai/DeepSeek-V3.2

### Hardware

NVIDIA H200 GPUs

### Engine Version

- vLLM: v0.13.0
- SGLang: v0.5.6.post2
- TensorRT-LLM: 1.2.0rc5

### Benchmark Dataset

1. ShareGPT
2. Random dataset with varying sequence lengths:
    - Very long prompt: 32000 input tokens, 100 output tokens
    - Long prompt: 4000 input tokens, 200 output tokens
    - Medium prompt: 2000 input tokens, 100 output tokens
    - Short prompt: 128 input tokens, 4 output tokens
    - Ultra Long Prompt: 128K input tokens, 100 output tokens
    - Generation-Heavy Prompt: 1K input tokens, 2K output tokens

### Benchmark Script

We use the **vLLM bench CLI** tool to benchmark the model performance. The following command is used to run the benchmark:

```bash
# Prepare the ShareGPT dataset
wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json

# Benchmark on ShareGPT dataset
vllm bench serve --model deepseek-ai/DeepSeek-V3.2 --backend openai-chat --endpoint /v1/chat/completions --dataset-name sharegpt --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json --num-prompts 1000

# Benchmark on random dataset (fixed seed for reproducibility)
vllm bench serve --model deepseek-ai/DeepSeek-V3.2 --backend openai-chat --endpoint /v1/chat/completions --dataset-name random --random-input-len 4000 --random-output-len 200 --num-prompts 500 --seed 42
```

## Experiment Results

### 1. Baseline of the Inference Engine

vLLM
??? info "Serving script"
    ```bash

    vllm serve deepseek-ai/DeepSeek-V3.2 -tp 8 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  76.59
    Total input tokens:                      219171
    Total generated tokens:                  200752
    Request throughput (req/s):              13.06
    Output token throughput (tok/s):         2621.05
    Peak output token throughput (tok/s):    7451.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          5482.59
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          17743.08
    Median TTFT (ms):                        17698.39
    P99 TTFT (ms):                           24371.87
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          227.45
    Median TPOT (ms):                        177.90
    P99 TPOT (ms):                           568.18
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           119.29
    Median ITL (ms):                         66.09
    P99 ITL (ms):                            384.38
    ==================================================
    ```

SGLang
??? info "Serving script"
    ```bash
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  138.25
    Total input tokens:                      219111
    Total generated tokens:                  197337
    Request throughput (req/s):              7.23
    Output token throughput (tok/s):         1427.44
    Peak output token throughput (tok/s):    7949.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          3012.37
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          11470.15
    Median TTFT (ms):                        11240.35
    P99 TTFT (ms):                           22363.90
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          1103.96
    Median TPOT (ms):                        672.86
    P99 TPOT (ms):                           4231.55
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           389.06
    Median ITL (ms):                         64.46
    P99 ITL (ms):                            3013.62
    ==================================================
    ```

TensorRT-LLM
??? info "Serving script"
    ```bash
    trtllm-serve /workspace/DeepSeek-v3.2 --tp_size 8
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     984
    Benchmark duration (s):                  236.70
    Total input tokens:                      215176
    Total generated tokens:                  194893
    Request throughput (req/s):              4.16
    Output token throughput (tok/s):         823.39
    Peak output token throughput (tok/s):    4212.00
    Peak concurrent requests:                984.00
    Total Token throughput (tok/s):          1732.48
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          65710.22
    Median TTFT (ms):                        66076.17
    P99 TTFT (ms):                           125723.14
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          1391.76
    Median TPOT (ms):                        608.74
    P99 TPOT (ms):                           4785.14
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           459.69
    Median ITL (ms):                         141.56
    P99 ITL (ms):                            4910.46
    ==================================================
    ```

Result: vLLM (5482.59 tok/s) > SGLang(3012.37 tok/s) > TensorRT-LLM (1732.48 tok/s)

### 2. Optimizing vLLM

#### Parallelism: DP+EP

??? info "Serving script"
    ```bash
    # 81920 is half context, full context OOM
    vllm serve deepseek-ai/DeepSeek-V3.2 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3 \
    -tp 1 -dp 8 --enable-expert-parallel --max-model-len 81920
    ```

??? info "Benchmark result"
    ```
    Successful requests:                     1000
    Benchmark duration (s):                  65.62
    Total input tokens:                      219111
    Total generated tokens:                  197109
    Request throughput (req/s):              15.24
    Output token throughput (tok/s):         3003.90
    Peak output token throughput (tok/s):    10222.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          6343.10
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          9144.24
    Median TTFT (ms):                        10233.68
    P99 TTFT (ms):                           14920.03
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          278.22
    Median TPOT (ms):                        115.72
    P99 TPOT (ms):                           2048.82
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           100.47
    Median ITL (ms):                         74.61
    P99 ITL (ms):                            1239.62
    ==================================================
    ```

#### Parallelism: DCP

??? info "Serving script"
    ```bash
    vllm serve deepseek-ai/DeepSeek-V3.2 -tp 8 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3 \
    -dcp 8
    ```

DeepSeek V3.2 relies on the FlashMLA sparse attention backend, which currently does not expose softmax log-sum-exp (LSE) during the decode phase. Since Decode Context Parallelism (DCP) requires softmax LSE for correct cross-rank aggregation, DCP is not supported with FlashMLA at this time, leading to a runtime failure in vLLM. This limitation has been discussed in the vLLM repository (see issue [#27544](https://github.com/vllm-project/vllm/issues/27544)).

#### MTP

??? info "Serving script"
    ```bash
    vllm serve deepseek-ai/DeepSeek-V3.2 -tp 8 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3 \
    --speculative-config {"method":"mtp","num_speculative_tokens":1}
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  74.35
    Total input tokens:                      219111
    Total generated tokens:                  196783
    Request throughput (req/s):              13.45
    Output token throughput (tok/s):         2646.63
    Peak output token throughput (tok/s):    3570.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          5593.57
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          12501.74
    Median TTFT (ms):                        12029.24
    P99 TTFT (ms):                           23027.37
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          241.34
    Median TPOT (ms):                        196.35
    P99 TPOT (ms):                           501.38
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           259.31
    Median ITL (ms):                         190.06
    P99 ITL (ms):                            814.86
    ==================================================
    ```

#### Turn off DeepGEMM in vLLM

??? info "Serving script"
    ```bash
    export VLLM_USE_DEEP_GEMM=0
    vllm serve deepseek-ai/DeepSeek-V3.2 -tp 8 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  85.38
    Total input tokens:                      219111
    Total generated tokens:                  197939
    Request throughput (req/s):              11.71
    Output token throughput (tok/s):         2318.22
    Peak output token throughput (tok/s):    6332.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          4884.39
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          13678.64
    Median TTFT (ms):                        13396.42
    P99 TTFT (ms):                           23105.42
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          346.54
    Median TPOT (ms):                        254.83
    P99 TPOT (ms):                           797.63
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           168.12
    Median ITL (ms):                         81.78
    P99 ITL (ms):                            689.16
    ==================================================
    ```

### 3. Optimizing SGLang

#### Parallelism: TP+DP Attention

??? info "Serving script"
    ```bash
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8 --enable-dp-attention
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  99.46
    Total input tokens:                      219111
    Total generated tokens:                  197633
    Request throughput (req/s):              10.05
    Output token throughput (tok/s):         1987.11
    Peak output token throughput (tok/s):    8911.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          4190.17
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          13679.11
    Median TTFT (ms):                        12663.74
    P99 TTFT (ms):                           21665.97
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          608.90
    Median TPOT (ms):                        398.19
    P99 TPOT (ms):                           3453.39
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           230.03
    Median ITL (ms):                         59.95
    P99 ITL (ms):                            1824.84
    ==================================================
    ```

#### Parallelism: TP+DP+DP Attention

??? info "Serving script"
    ```bash
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8 --dp-size 8 --enable-dp-attention
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  56.62
    Total input tokens:                      219111
    Total generated tokens:                  197116
    Request throughput (req/s):              17.66
    Output token throughput (tok/s):         3481.55
    Peak output token throughput (tok/s):    11298.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          7351.59
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          7815.00
    Median TTFT (ms):                        8024.81
    P99 TTFT (ms):                           12928.46
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          287.86
    Median TPOT (ms):                        107.58
    P99 TPOT (ms):                           2096.18
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           91.68
    Median ITL (ms):                         58.87
    P99 ITL (ms):                            317.43
    ==================================================
    ```

#### Parallelism: TP+DP+DP Attention+EP

??? info "Serving script"
    ```bash
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8 --dp-size 8 --enable-dp-attention --ep-size 8
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  57.14
    Total input tokens:                      219111
    Total generated tokens:                  197614
    Request throughput (req/s):              17.50
    Output token throughput (tok/s):         3458.68
    Peak output token throughput (tok/s):    11757.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          7293.61
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          8437.36
    Median TTFT (ms):                        8346.50
    P99 TTFT (ms):                           15410.07
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          319.46
    Median TPOT (ms):                        111.65
    P99 TPOT (ms):                           2443.91
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           94.48
    Median ITL (ms):                         56.54
    P99 ITL (ms):                            451.92
    ==================================================
    ```

#### MTP

??? info "Serving script"
    ```bash
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --tp-size 8 \
    --speculative-algorithm EAGLE --speculative-num-steps 1 --speculative-eagle-topk 1 --speculative-num-draft-tokens 2
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  278.36
    Total input tokens:                      219111
    Total generated tokens:                  193349
    Request throughput (req/s):              3.59
    Output token throughput (tok/s):         694.61
    Peak output token throughput (tok/s):    974.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          1481.77
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          139046.94
    Median TTFT (ms):                        144733.94
    P99 TTFT (ms):                           260932.68
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          68.88
    Median TPOT (ms):                        63.31
    P99 TPOT (ms):                           280.02
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           115.50
    Median ITL (ms):                         48.42
    P99 ITL (ms):                            337.68
    ==================================================
    ```

#### Turn off DeepGEMM

??? info "Serving script"
    ```bash
    export SGLANG_ENABLE_JIT_DEEPGEMM=0
    python3 -m sglang.launch_server --model-path deepseek-ai/DeepSeek-V3.2 --host 0.0.0.0 --port 8000 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8
    ```

The server fails to start when DeepGEMM is disabled.


### 4. Optimizing TensorRT-LLM

#### Parallelism: TP+EP

??? info "Serving script"
    ```bash
    trtllm-serve /workspace/DeepSeek-v3.2 --tp_size 8 --ep_size 8 --pp_size 1
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     984
    Benchmark duration (s):                  142.99
    Total input tokens:                      216405
    Total generated tokens:                  195740
    Request throughput (req/s):              6.88
    Output token throughput (tok/s):         1368.90
    Peak output token throughput (tok/s):    4635.00
    Peak concurrent requests:                984.00
    Total Token throughput (tok/s):          2882.32
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          24155.45
    Median TTFT (ms):                        23945.42
    P99 TTFT (ms):                           45683.09
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          561.24
    Median TPOT (ms):                        312.75
    P99 TPOT (ms):                           1473.03
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           248.40
    Median ITL (ms):                         142.18
    P99 ITL (ms):                            1819.83
    ==================================================
    ```

#### Turn off DeepGEMM

??? info "Serving script"
    ```bash
    export TRTLLM_DG_ENABLED=0
    trtllm-serve /workspace/DeepSeek-v3.2 --tp_size 8 --ep_size 8 --pp_size 1
    ```

??? info "Benchmark result"
    ```
    ============ Serving Benchmark Result ============
    Successful requests:                     984
    Benchmark duration (s):                  134.65
    Total input tokens:                      216484
    Total generated tokens:                  194509
    Request throughput (req/s):              7.31
    Output token throughput (tok/s):         1444.56
    Peak output token throughput (tok/s):    4661.00
    Peak concurrent requests:                984.00
    Total Token throughput (tok/s):          3052.33
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          23229.65
    Median TTFT (ms):                        23100.28
    P99 TTFT (ms):                           44648.94
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          541.07
    Median TPOT (ms):                        264.04
    P99 TPOT (ms):                           1588.04
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           226.30
    Median ITL (ms):                         137.80
    P99 ITL (ms):                            1624.47
    ==================================================
    ```

### Summary of Optimization Options

| Optimization Option | Throughput Improvement                                   |
| ------------------- | -------------------------------------------------------- |
| Parallelism         | <span style="background-color:lightgreen;">+78.7%</span> |
| MTP                 | -                                                        |
| DeepGEMM            | -                                                        |

### Other Benchmark Cases

We further benchmarked the optimized configuration to evaluate its generalization under various workloads.

??? info "Baseline serving script"
    ```bash
    vllm serve deepseek-ai/DeepSeek-V3.2 -tp 8 --tokenizer-mode deepseek_v32 --reasoning-parser deepseek_v3
    ```

??? info "Baseline benchmark results"
    ```bash
    # random 128 input
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  12.52
    Total input tokens:                      128000
    Total generated tokens:                  4000
    Request throughput (req/s):              79.84
    Output token throughput (tok/s):         319.37
    Peak output token throughput (tok/s):    1038.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          10539.36
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          5621.20
    Median TTFT (ms):                        4538.46
    P99 TTFT (ms):                           12357.11
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          747.47
    Median TPOT (ms):                        669.25
    P99 TPOT (ms):                           1514.56
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           561.02
    Median ITL (ms):                         647.20
    P99 ITL (ms):                            3245.15
    ==================================================


    # random 2K input
    ============ Serving Benchmark Result ============
    Successful requests:                     500
    Benchmark duration (s):                  100.11
    Total input tokens:                      1000000
    Total generated tokens:                  50000
    Request throughput (req/s):              4.99
    Output token throughput (tok/s):         499.44
    Peak output token throughput (tok/s):    4304.00
    Peak concurrent requests:                500.00
    Total Token throughput (tok/s):          10488.24
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          46255.96
    Median TTFT (ms):                        43150.42
    P99 TTFT (ms):                           89117.06
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          375.72
    Median TPOT (ms):                        452.73
    P99 TPOT (ms):                           475.13
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           374.66
    Median ITL (ms):                         61.23
    P99 ITL (ms):                            3011.50
    ==================================================

    # random 4K input
    ============ Serving Benchmark Result ============
    Successful requests:                     500
    Benchmark duration (s):                  225.49
    Total input tokens:                      2000000
    Total generated tokens:                  100000
    Request throughput (req/s):              2.22
    Output token throughput (tok/s):         443.48
    Peak output token throughput (tok/s):    2800.00
    Peak concurrent requests:                500.00
    Total Token throughput (tok/s):          9313.06
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          108539.85
    Median TTFT (ms):                        95734.59
    P99 TTFT (ms):                           215869.24
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          245.07
    Median TPOT (ms):                        286.28
    P99 TPOT (ms):                           316.31
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           247.58
    Median ITL (ms):                         46.40
    P99 ITL (ms):                            676.98
    ==================================================


    # random 32k input
    ============ Serving Benchmark Result ============
    Successful requests:                     100
    Benchmark duration (s):                  327.90
    Total input tokens:                      3200000
    Total generated tokens:                  10000
    Request throughput (req/s):              0.30
    Output token throughput (tok/s):         30.50
    Peak output token throughput (tok/s):    388.00
    Peak concurrent requests:                100.00
    Total Token throughput (tok/s):          9789.64
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          162297.42
    Median TTFT (ms):                        162438.41
    P99 TTFT (ms):                           321700.94
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          463.89
    Median TPOT (ms):                        499.75
    P99 TPOT (ms):                           508.28
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           474.09
    Median ITL (ms):                         730.66
    P99 ITL (ms):                            1619.85
    ==================================================

    # random 128K input
    ============ Serving Benchmark Result ============
    Successful requests:                     100
    Benchmark duration (s):                  2037.13
    Total input tokens:                      12800000
    Total generated tokens:                  10000
    Request throughput (req/s):              0.05
    Output token throughput (tok/s):         4.91
    Peak output token throughput (tok/s):    161.00
    Peak concurrent requests:                100.00
    Total Token throughput (tok/s):          6288.25
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          1018221.01
    Median TTFT (ms):                        1018261.60
    P99 TTFT (ms):                           2014519.85
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          619.71
    Median TPOT (ms):                        633.66
    P99 TPOT (ms):                           636.29
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           672.49
    Median ITL (ms):                         48.45
    P99 ITL (ms):                            3098.07
    ==================================================
    ```

??? info "Optimized serving script"
    ```bash
    python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-V3.2 \
    --chat-template ./tool_chat_template_deepseekv32.jinja \
    --tp-size 8 --dp-size 8 --enable-dp-attention
    ```

??? info "Optimized benchmark results"
    ```bash
    # random 128 input
    ============ Serving Benchmark Result ============
    Successful requests:                     1000
    Benchmark duration (s):                  6.67
    Total input tokens:                      128000
    Total generated tokens:                  4000
    Request throughput (req/s):              149.84
    Output token throughput (tok/s):         599.35
    Peak output token throughput (tok/s):    4024.00
    Peak concurrent requests:                1000.00
    Total Token throughput (tok/s):          19778.53
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          4099.90
    Median TTFT (ms):                        4098.17
    P99 TTFT (ms):                           6317.59
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          753.97
    Median TPOT (ms):                        757.13
    P99 TPOT (ms):                           1503.80
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           452.38
    Median ITL (ms):                         47.46
    P99 ITL (ms):                            4119.27
    ==================================================


    # random 2K input
    ============ Serving Benchmark Result ============
    Successful requests:                     500
    Benchmark duration (s):                  38.34
    Total input tokens:                      1000000
    Total generated tokens:                  50000
    Request throughput (req/s):              13.04
    Output token throughput (tok/s):         1304.09
    Peak output token throughput (tok/s):    9483.00
    Peak concurrent requests:                500.00
    Total Token throughput (tok/s):          27385.86
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          18352.43
    Median TTFT (ms):                        18213.72
    P99 TTFT (ms):                           32610.24
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          200.34
    Median TPOT (ms):                        200.06
    P99 TPOT (ms):                           352.65
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           197.27
    Median ITL (ms):                         54.70
    P99 ITL (ms):                            184.54
    ==================================================

    # random 4K input
    ============ Serving Benchmark Result ============
    Successful requests:                     500
    Benchmark duration (s):                  104.51
    Total input tokens:                      2000000
    Total generated tokens:                  100000
    Request throughput (req/s):              4.78
    Output token throughput (tok/s):         956.89
    Peak output token throughput (tok/s):    7126.00
    Peak concurrent requests:                500.00
    Total Token throughput (tok/s):          20094.60
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          47739.77
    Median TTFT (ms):                        45502.07
    P99 TTFT (ms):                           93725.95
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          171.34
    Median TPOT (ms):                        150.82
    P99 TPOT (ms):                           331.21
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           170.92
    Median ITL (ms):                         50.15
    P99 ITL (ms):                            234.79
    ==================================================


    # random 32k input
    ============ Serving Benchmark Result ============
    Successful requests:                     100
    Benchmark duration (s):                  160.32
    Total input tokens:                      3200000
    Total generated tokens:                  10000
    Request throughput (req/s):              0.62
    Output token throughput (tok/s):         62.38
    Peak output token throughput (tok/s):    1240.00
    Peak concurrent requests:                100.00
    Total Token throughput (tok/s):          20022.76
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          83622.72
    Median TTFT (ms):                        87712.84
    P99 TTFT (ms):                           157285.48
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          245.69
    Median TPOT (ms):                        239.81
    P99 TPOT (ms):                           508.93
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           244.68
    Median ITL (ms):                         33.38
    P99 ITL (ms):                            880.61
    ==================================================

    # random 128k input
    ============ Serving Benchmark Result ============
    Successful requests:                     50
    Benchmark duration (s):                  389.54
    Total input tokens:                      6400000
    Total generated tokens:                  5000
    Request throughput (req/s):              0.13
    Output token throughput (tok/s):         12.84
    Peak output token throughput (tok/s):    330.00
    Peak concurrent requests:                50.00
    Total Token throughput (tok/s):          16442.29
    ---------------Time to First Token----------------
    Mean TTFT (ms):                          208784.94
    Median TTFT (ms):                        228521.00
    P99 TTFT (ms):                           386624.08
    -----Time per Output Token (excl. 1st token)------
    Mean TPOT (ms):                          51.45
    Median TPOT (ms):                        48.29
    P99 TPOT (ms):                           74.02
    ---------------Inter-token Latency----------------
    Mean ITL (ms):                           50.95
    Median ITL (ms):                         24.63
    P99 ITL (ms):                            430.95
    ==================================================
    ```
