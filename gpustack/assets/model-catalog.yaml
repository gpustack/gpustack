draft_models:
- name: Qwen3-8B-EAGLE3
  algorithm: eagle3
  source: huggingface
  huggingface_repo_id: Tengyunw/qwen3_8b_eagle3
- name: Qwen3-30B-A3B-EAGLE3
  algorithm: eagle3
  source: huggingface
  huggingface_repo_id: Tengyunw/qwen3_30b_moe_eagle3
- name: Qwen3-235B-A22B-EAGLE3
  algorithm: eagle3
  source: huggingface
  huggingface_repo_id: lmsys/Qwen3-235B-A22B-EAGLE3
- name: gpt-oss-120b-EAGLE3
  algorithm: eagle3
  source: huggingface
  huggingface_repo_id: lmsys/EAGLE3-gpt-oss-120b-bf16
model_sets:
- name: Qwen3 0.6B
  description: Qwen3 is a family of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 0.6
  categories:
    - llm
  capabilities:
    - context/128K
    - tools
  licenses:
    - apache-2.0
  release_date: "2025-07-21"
  specs:
    - mode: standard
      quantization: BF16
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-0.6B
      backend: vLLM
      backend_parameters:
        - --reasoning-parser=deepseek_r1
        - --max-model-len=8192
- name: Qwen3 30B A3B
  description: Qwen3 is a family of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 30
  activated_size: 3 
  categories:
    - llm
  capabilities:
    - context/128K
    - tools
  licenses:
    - apache-2.0
  release_date: "2025-07-21"
  specs:
    - mode: standard
      quantization: BF16
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-30B-A3B
      backend: vLLM
      backend_parameters:
        - --tool-call-parser=hermes
        - --enable-auto-tool-choice
        - --max-model-len=32768
- name: GLM-4.6
  description: GLM-4.6 is a large language model developed by Zhipu AI, featuring advanced agentic, reasoning, and coding capabilities.
  home: https://z.ai
  icon: /static/catalog_icons/zai.png
  size: 355
  activated_size: 32
  categories:
    - llm
  capabilities:
    - context/1M
    - reasoning
    - tools
  licenses:
    - mit
  release_date: "2025-09-30"
  specs:
    - mode: standard
      quantization: BF16
      source: huggingface
      huggingface_repo_id: zai-org/GLM-4.6
      backend: vLLM
      backend_parameters:
        - --reasoning-parser=glm45
        - --tool-call-parser=glm45
        - --enable-auto-tool-choice
        - --max-model-len=32768
- name: gpt-oss 120B
  description: The gpt-oss series is OpenAI's family of open-weight models, designed for powerful reasoning, agentic tasks, and versatile developer use cases.
  home: https://openai.com
  icon: /static/catalog_icons/openai.png
  categories:
    - llm
  capabilities:
    - context/128K
  size: 120
  licenses:
    - apache-2.0
  release_date: "2025-08-05"
  specs:
    - mode: standard
      quantization: "MXFP4"
      source: huggingface
      huggingface_repo_id: openai/gpt-oss-120b
      backend: vllm
      backend_parameters:
        - --max-model-len=32768
        - --tool-call-parser=openai
        - --enable-auto-tool-choice
- name: gpt-oss 20B
  description: The gpt-oss series is OpenAI's family of open-weight models, designed for powerful reasoning, agentic tasks, and versatile developer use cases.
  home: https://openai.com
  icon: /static/catalog_icons/openai.png
  categories:
    - llm
  capabilities:
    - context/128K
  size: 20
  licenses:
    - apache-2.0
  release_date: "2025-08-05"
  specs:
    - mode: standard
      quantization: "MXFP4"
      source: huggingface
      huggingface_repo_id: openai/gpt-oss-20b
      backend: vllm
      backend_parameters:
        - --max-model-len=32768
        - --tool-call-parser=openai
        - --enable-auto-tool-choice
- name: Deepseek R1 0528
  description: DeepSeek-R1-0528 is a minor version of the DeepSeek R1 model that features enhanced reasoning depth and inference capabilities. These improvements are achieved through increased computational resources and algorithmic optimizations applied during post-training. The model delivers strong performance across a range of benchmark evaluations, including mathematics, programming, and general logic, with overall capabilities approaching those of leading models such as O3 and Gemini 2.5 Pro.
  home: https://www.deepseek.com
  icon: /static/catalog_icons/deepseek.png
  categories:
    - llm
  capabilities:
    - context/128K
  size: 671
  licenses:
    - mit
  release_date: "2025-05-28"
  specs:
    - mode: standard
      quantization: FP8
      source: huggingface
      huggingface_repo_id: deepseek-ai/DeepSeek-R1-0528
      backend: vLLM
      backend_parameters:
        - --max-model-len=32768
# Embedding models
- name: Qwen3 Embedding 0.6B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 0.6
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-0.6B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
- name: Qwen3 Embedding 4B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 4
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-4B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
- name: Qwen3 Embedding 8B
  description: Qwen3-Embedding is a multilingual embedding model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 8
  categories:
    - embedding
  capabilities:
    - dimensions/4096
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Embedding-8B
      categories:
        - embedding
      backend: vLLM
      backend_parameters:
        - --task=embed
# Reranker models
- name: Qwen3 Reranker 0.6B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 0.6
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-0.6B
      categories:
        - reranker
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
- name: Qwen3 Reranker 4B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 4
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-4B
      categories:
        - reranker
      env:
        GPUSTACK_APPLY_QWEN3_RERANKER_TEMPLATES: "true"
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
- name: Qwen3 Reranker 8B
  description: Qwen3-Reranker is a multilingual text reranking model series optimized for retrieval, clustering, classification, and bitext mining. It supports 100+ languages, with flexible vector dimensions and instruction tuning.
  home: https://qwenlm.github.io
  icon: /static/catalog_icons/qwen.png
  size: 8
  categories:
    - reranker
  capabilities:
    - max_tokens/32K
  licenses:
    - apache-2.0
  release_date: "2025-06-09"
  specs:
    - mode: standard
      quantization: "BF16"
      source: huggingface
      huggingface_repo_id: Qwen/Qwen3-Reranker-8B
      categories:
        - reranker
      backend: vLLM
      backend_parameters:
        - '--hf_overrides={"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
        - --task=score
